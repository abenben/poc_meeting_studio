# **詳細設計書：AI議事録作成・活用システム**

## 1. 概要

### 1.1. プロジェクト目的
本プロジェクトは、Google Meetの録画データから高精度な文字起こしを行い、AIを用いて「要約」「決定事項」「アクションプラン」を自動で構造化するシステムを開発する。これにより、議事録作成工数の大幅な削減、情報共有の質の向上、そしてアクションプランの確実な実行を支援し、会議を中心とした業務プロセス全体の生産性向上を目指す。

### 1.2. 本ドキュメントの目的
本ドキュメントは、開発するシステムのアーキテクチャ、技術スタック、機能仕様、データモデル、API設計などの詳細を定義し、開発チーム間の共通認識を形成することを目的とする。

## 2. システムアーキテクチャ

システム全体の構成は以下の通り。ユーザーからのリクエストを受け付け、Google Cloudの各種サービスと連携して処理を行い、結果をWebアプリケーションとして提供する。

```mermaid
graph TD
    subgraph User Interaction
        J((ユーザー)) -- 1. 録画ファイルアップロード --> I;
        I -- 6. 編集・閲覧・進捗管理 --> J;
    end

    subgraph System Backend & Frontend
        I[Webアプリケーション (フロントエンド)] -- 2. 処理リクエスト --> H[バックエンドサーバー (API)];
        H -- 7. データ要求/更新 --> G[データベース];
    end

    subgraph Google Cloud Services
        H -- 3. 音声処理依頼 --> C[Cloud Speech-to-Text API];
        C -- 4. 文字起こしテキスト --> H;
        H -- 5. 構造化依頼 --> E[Google AI Platform (Gemini API)];
        E -- 構造化データ(JSON) --> H;
    end

    G[データベース] <--> H;

    style J fill:#f9f,stroke:#333,stroke-width:2px
```

### 2.1. コンポーネントの役割
- **Webアプリケーション (フロントエンド)**: ユーザーが操作するインターフェース。ファイルアップロード、議事録の表示・編集、アクションプランのステータス管理、エクスポート機能を提供する。
- **バックエンドサーバー (API)**: ビジネスロジックの中核。フロントエンドからのリクエストを受け、外部API（Speech-to-Text, Gemini）との連携、データベースへの読み書きを行う。
- **データベース**: 議事録、アクションプラン、ユーザー情報などの永続データを保存する。
- **Google Cloud Services**: 高度なAI処理（音声認識、自然言語処理）を担うマネージドサービス。

## 3. 技術スタック

| 分類 | 技術 | 備考 |
| :--- | :--- | :--- |
| **フロントエンド** | React (Next.js) または Vue.js (Nuxt.js) | SPAとして高速なUI/UXを実現。 |
| **バックエンド** | Python (FastAPI) または Node.js (Express) | AI/MLライブラリとの親和性からPython(FastAPI)を推奨。 |
| **データベース** | PostgreSQL (Cloud SQL) または Firestore | リレーショナルなデータ構造のためPostgreSQLを推奨。 |
| **AI / ML** | Google Cloud Speech-to-Text API | 高精度な文字起こしと話者分離に利用。 |
| | Google AI Platform (Gemini API) | 文字起こしテキストの要約、構造化に利用。 |
| **インフラ** | Google Cloud | Cloud Run (バックエンド), Firebase Hosting (フロントエンド) など。 |
| **認証** | Firebase Authentication または Google Identity | GoogleアカウントでのSSO（シングルサインオン）を実装。 |

## 4. 機能仕様詳細

### 4.1. 高精度文字起こし (F-01)
- **概要**: アップロードされた音声ファイルから高精度な文字起こしテキストを生成する。
- **入力**: ユーザーがアップロードした音声ファイル（MP3, WAV, M4A等）。
- **処理**:
    1. バックエンドは音声ファイルを受け取り、Cloud Storageに保存。
    2. Cloud Speech-to-Text APIの非同期認識（long-running-recognize）ジョブを開始。
    3. 設定項目：
        - `languageCode`: "ja-JP"
        - `enableAutomaticPunctuation`: `true` (自動句読点)
        - `enableSpeakerDiarization`: `true` (話者分離)
    4. 処理完了後、タイムスタンプと話者タグ付きのテキストデータを取得し、DBに保存する。
- **出力**: 話者情報を含むJSON形式の文字起こしデータ。

### 4.2. 議事録の自動構造化 (F-02)
- **概要**: 文字起こしテキストをAIが解析し、要約・決定事項・アクションプランを抽出する。
- **入力**: F-01で生成された文字起こしテキスト。
- **処理**:
    1. バックエンドは、DBから文字起こしテキストを取得。
    2. 事前に定義されたプロンプトテンプレートにテキストを埋め込み、Gemini APIにリクエストを送信。
    3. APIからのレスポンス（JSON形式を期待）をパースし、DBの各テーブル（Minutes, ActionItems）に保存する。
- **出力**: 構造化された議事録データ（JSON形式）。
- **プロンプト設計 (基本形)**:
  ```prompt
  あなたは、非常に優秀なビジネスアシスタントです。
  以下の会議の文字起こしテキストを分析し、下記のJSONフォーマットに従って議事録の要素を抽出してください。

  # 指示
  - 会議全体の要点を3点にまとめてください。
  - 議論の結果、確定した「決定事項」をすべてリストアップしてください。
  - 「誰が」「何を」「いつまでに行うか」を明確にした「アクションプラン」をリストアップしてください。担当者や期限が不明な場合は、該当する値を "要確認" としてください。

  # 出力フォーマット (JSON)
  {
    "summary": [
      "要点1",
      "要点2",
      "要点3"
    ],
    "decisions": [
      "決定事項1",
      "決定事項2"
    ],
    "action_items": [
      {
        "task": "タスク内容1",
        "assignee": "担当者名1",
        "due_date": "YYYY-MM-DD形式の期限1"
      },
      {
        "task": "タスク内容2",
        "assignee": "担当者名2",
        "due_date": "YYYY-MM-DD形式の期限2"
      }
    ]
  }

  # 文字起こしテキスト
  ---
  {raw_transcript_text}
  ---
  ```

### 4.3. 手動編集インターフェース (F-03)
- **概要**: AIが生成した議事録をユーザーが手動で修正・追記できるUIを提供する。
- **表示**:
    - 「要約」「決定事項」はリッチテキストエディタで表示。
    - 「アクションプラン」はテーブル形式で表示し、各セルが編集可能。
- **操作**:
    - テキストのインライン編集。
    - アクションプランの行追加、削除機能。
    - 担当者、期限はカレンダーピッカー等で入力補助。
    - 変更内容は自動保存、または「保存」ボタンでDBに反映。

### 4.4. アクションプラン管理 (F-04)
- **概要**: 議事録から抽出されたアクションプランの進捗を管理する。
- **機能**:
    - **議事録単位表示**: 各議事録ページ内で、紐づくアクションプランのステータス（未着手/進行中/完了）をドロップダウン等で更新できる。
    - **ダッシュボード表示**: ユーザーが担当する全てのアクションプランを、議事録を横断して一覧表示。期限やステータスでのソート・フィルタリングが可能。
- **ステータス**: `todo` (未着手), `doing` (進行中), `done` (完了)

### 4.5. エクスポート機能 (F-05)
- **概要**: 生成・編集した議事録を外部で利用できる形式で出力する。
- **操作**: 議事録ページの「エクスポート」ボタンをクリックし、形式（Markdown / テキスト）を選択。
- **出力 (Markdown形式の例)**:
  ```markdown
  # 議事録：{会議タイトル}

  - **開催日時**: {会議開催日}
  - **参加者**: {参加者リスト} ※手動入力項目

  ## 1. 会議の要約
  - 要点1
  - 要点2
  - 要点3

  ## 2. 決定事項
  - 決定事項1
  - 決定事項2

  ## 3. アクションプラン (ToDo)
  | タスク内容 | 担当者 | 期限 | ステータス |
  |:---|:---|:---|:---|
  | タスク内容1 | 担当者1 | YYYY-MM-DD | 未着手 |
  | タスク内容2 | 担当者2 | YYYY-MM-DD | 進行中 |
  ```

## 5. データモデル設計 (主要なもの)

### `meetings` テーブル
| カラム名 | データ型 | 説明 |
| :--- | :--- | :--- |
| `id` | UUID | 主キー |
| `title` | VARCHAR(255) | 会議のタイトル |
| `meeting_date` | TIMESTAMP | 会議の開催日時 |
| `gcs_audio_uri` | VARCHAR(255) | Cloud Storage上の音声ファイルURI |
| `transcript_job_id` | VARCHAR(255) | Speech-to-TextのジョブID |
| `raw_transcript` | JSONB | 話者情報付きの文字起こし全文 |
| `status` | VARCHAR(50) | 処理ステータス (`processing`, `processed`, `error`) |
| `created_at` | TIMESTAMP | レコード作成日時 |
| `user_id` | UUID | 作成したユーザーID |

### `minutes` テーブル
| カラム名 | データ型 | 説明 |
| :--- | :--- | :--- |
| `id` | UUID | 主キー |
| `meeting_id` | UUID | `meetings`テーブルへの外部キー |
| `summary` | TEXT | 要約 |
| `decisions` | TEXT | 決定事項（Markdown or JSON） |
| `created_at` | TIMESTAMP | レコード作成日時 |
| `updated_at` | TIMESTAMP | レコード最終更新日時 |

### `action_items` テーブル
| カラム名 | データ型 | 説明 |
| :--- | :--- | :--- |
| `id` | UUID | 主キー |
| `minutes_id` | UUID | `minutes`テーブルへの外部キー |
| `task_description`| TEXT | タスク内容 |
| `assignee` | VARCHAR(100) | 担当者名 |
| `due_date` | DATE | 期限 |
| `status` | VARCHAR(50) | `todo`, `doing`, `done` |
| `created_at` | TIMESTAMP | レコード作成日時 |
| `updated_at` | TIMESTAMP | レコード最終更新日時 |

## 6. APIエンドポイント設計 (主要なもの)

- `POST /v1/meetings`: 新規会議の登録（音声ファイルアップロード）
- `GET /v1/meetings/{meeting_id}`: 会議情報と処理ステータスの取得
- `GET /v1/meetings/{meeting_id}/minutes`: 構造化された議事録データの取得
- `PUT /v1/meetings/{meeting_id}/minutes`: ユーザーが編集した議事録データを更新
- `GET /v1/action-items`: 自身が担当するアクションアイテムの一覧取得 (クエリパラメータでフィルタ)
- `PUT /v1/action-items/{item_id}`: アクションアイテムのステータス更新

## 7. 非機能要件

| 要件 | 内容 |
| :--- | :--- |
| **セキュリティ** | ・全ての通信はTLSで暗号化。<br>・GoogleアカウントによるOAuth 2.0認証を導入。<br>・APIキー等の機密情報はSecret Managerで管理。 |
| **パフォーマンス** | ・音声認識とAI構造化は非同期ジョブとして実行し、完了を待たずにUI操作を可能にする。<br>・フロントエンドはSSR/SSGを活用し、初期表示速度を最適化。 |
| **コスト管理** | ・API利用量の上限設定とアラートをGoogle Cloud上で構成。<br>・長時間音声の処理コストを事前にユーザーに通知するUIを検討。 |
| **可用性** | ・サーバーレスアーキテクチャ（Cloud Run等）を採用し、高可用性を担保。<br>・定期的なDBバックアップを設定。 |

## 8. 開発ロードマップ

| フェーズ | 期間（目安） | 主なゴール |
| :--- | :--- | :--- |
| **1. PoC** | 1-2週間 | AIによる構造化（F-02）の技術的実現性を検証する。 |
| **2. MVP開発** | 1-2ヶ月 | F-02, F-03, F-05の最小限の機能で、一連の業務フローを体験できる製品を開発。 |
| **3. ベータ版開発** | 2-3ヶ月 | F-01, F-04を追加実装し、特定部署で実運用を開始。フィードバックを収集。 |
| **4. 本格展開** | 継続 | 全社展開と、フィードバックに基づく機能改善・拡張。 |